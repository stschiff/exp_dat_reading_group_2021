---
title: "Lesson 1: Fill in missing data"
author: "Clemens Schmid"
date: "10/13/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Missing data

Missing information is one of the core challenges for working with ancient DNA data. Here we want to explore its effect on PCA.

### Dependencies

This analysis relies on a number of R packages. You can install them with the following command:

```{r,results=F}
packages <- c("tidyverse", "missMethods", "cowplot", "ggrepel")
Map(function(x) { install.packages(x) }, packages[!packages %in% utils::installed.packages()])
```

We also have to load two packages and fix the seed for all random operations.

```{r}
library(magrittr)
library(ggplot2)
set.seed(123)
```

### Dataset

We prepared a simplified genotype dataset, which should allow you to consider the effect of missingness in the (familiar?) environment of world-wide population structure. It contains one individual each from about 50 populations from around the world. The `context_info` table holds some minimal context information.

```{r,message=F}
context_info <- readr::read_csv("context_info_one.csv")
context_info
```

```{r,warning=FALSE}
world <- map_data("world")
ggplot() +
  geom_map(data = world, map = world, aes(long, lat, map_id = region)) +
  geom_point(data = context_info, aes(Longitude, Latitude, colour = Makro_Region), size = 3) +
  coord_fixed()
```

For each individual we extracted the same <50000 non-missing SNPs from the HumanOrigins SNP array ([Patterson 2012](https://doi.org/10.1534/genetics.112.145037)). They are available in a large `geno_matrix` text file, that can be loaded into R like this:

```{r}
geno_matrix <- scan("geno_matrix_one.txt", what = "character") %>%
  strsplit("") %>%
  do.call(rbind, .) %>%
  apply(., 2, as.numeric)
```

This large matrix contains more than 2 million entries and requires about 20MB of memory. Nevertheless we can still conveniently and interactively work with it in R. It features `r nrow(geno_matrix)` rows, one for each individual, and one column for each of the `r ncol(geno_matrix)` SNPs. Each cell has either the value 0, 1 or 2 and -- although this is technically discrete data -- we'll treat it as continuously scaled.

```{r}
str(geno_matrix)
```

### Running PCA

To explore this complex dataset we can run PCA on it, e.g. with `stats::prcomp()`:

```{r}
pca <- prcomp(geno_matrix)
```

Note how surprisingly fast the computation completes. The output object of this function is a complex beast, though.

```{r}
str(pca)
```

Fortunately, most of the time we're only interested in three fields for concrete applications:

- `$sdev`: standard deviations of the principal components
- `$rotation`: the matrix of variable loadings
- `$x`: the value of the rotated data (so: the coordinates of our input observations in PCA space)

From the standard deviations (`$sdev`) we can calculate the proportions of variance covered by the individual principal components:

```{r}
pov <- pca$sdev^2/sum(pca$sdev^2)
pov_df <- tibble::tibble(pc = as.factor(1:10), pov = pov[1:10])
pov_df %>% ggplot() + geom_bar(aes(pc, pov), stat = "identity")
```

The variable loadings (`$rotation`) can be explored individually (though it's a bit tedious for tens of thousands of SNPs) or used for projection (see lesson 2).

The output coordinates (`$x`) finally are most immediately useful to plot a "genetic map". 

```{r}
pca$x %>% 
  as.data.frame() %>%
  ggplot() +
  geom_point(aes(PC1, PC2))
```

This alone is of doubtful usefulness, as we can't really interpret a random, unlabelled point cloud. We have to add meaningful context information. Fortunately we already have this available in the `context_info` object` and can combine the two.

```{r}
pca_tidy_obs <- pca$x %>%
  tibble::as_tibble() %>%
  dplyr::bind_cols(context_info)

pca_tidy_obs[c(1,2,(ncol(pca_tidy_obs)-5):ncol(pca_tidy_obs))]
```

With this context data, the PCA plot can be rendered a lot more informative and useful.

```{r}
pca_tidy_obs %>%
  ggplot() +
  geom_point(aes(PC1, PC2, color = Makro_Region))
```

We automated the described data preparation and plotting operations with a number of helper functions in a supplementary script file.

```{r}
source("helper_functions.R")

prcomp(geno_matrix) %>%
  tidy_pca_output() %>%
  plot_tidy_pca_simple(ggrepel::geom_text_repel, max.overlaps = Inf, use.labels = 'all')

prcomp(geno_matrix) %>%
  tidy_pca_output() %>%
  plot_tidy_pca_density()
```

[Let's discuss these plots!]

### Creating missing data

To explore the effect of missing data on the PCA plot, we can artificially modify our currently complete dataset. Figuratively we can "shoot holes" into it. Here's a simple matrix:

```{r}
x <- matrix(1:9, nrow = 3, ncol = 3, byrow = T)
x
```

We can poke holes into it with a function like this:

```{r}
# shoot_holes()
destruction_level <- 0.3 # desired percentage of missingness
nr_holes <- round(destruction_level * prod(dim(x)))
holes <- sample(seq_along(x), size = nr_holes)
x_Emmentaler <- x
x_Emmentaler[holes] <- NA
x_Emmentaler
```

This implementation has one issue: it can accidentally wipe out entire columns. We want to avoid that for this experiment, so here's an alternative implementation that removes the same proportion of values from each column.

```{r}
# shoot_holes_column_wise()
destruction_level <- 0.3 # desired percentage of missingness
nr_holes_per_column <- round((destruction_level * prod(dim(x)))/ncol(x))
x_Tilsit <- apply(x, 2, function(y) {
  holes <- sample(seq_along(y), size = nr_holes_per_column)
  y[holes] <- NA
  y
})
x_Tilsit
```

Equipped like this we can start to poke holes into our genotype data and run PCA on it.

```{r,error=TRUE}
geno_perforated <- shoot_holes_column_wise(geno_matrix, 0.3)
prcomp(geno_perforated)
```

This yields a nasty error message. `stats::prcomp()` can not run with perforated input data. So we're forced to patch the holes.

### Filling missing data

#### Mean imputation

Mean imputation fills the missing values with the means of some observed values. We can write a column-wise mean imputation like this:

```{r}
patch_holes_mean <- function(x) {
  apply(x, 2, function(y) { 
    y[is.na(y)] <- mean(y, na.rm = T)
    y
  })
}
```

... and then run it on our perforated dataset:

```{r}
geno_matrix %>%
  shoot_holes_column_wise(0.5) %>%
  patch_holes_mean() %>%
  prcomp(geno_matrix) %>%
  tidy_pca_output() %>%
  plot_tidy_pca_simple()
```

The R package `missingMethods` provides a number of imputation algorithms, including the following three for mean imputation: `impute_mean()`, `impute_median()`, and `impute_mode`. The first one should behave identically to our own implementation `patch_holes_mean()`. We can compare their effects with the helper function `explore_filling_method()`, which wraps the whole pipeline from data, to imputation, to plot.

```{r}
geno_matrix %>% explore_filling_method(missMethods::impute_mean, destruction_level = 0.5)
geno_matrix %>% explore_filling_method(missMethods::impute_median, 0.5)
geno_matrix %>% explore_filling_method(missMethods::impute_mode, 0.5)
```

[Let's play with these functions. Do they differ? Modify the `destruction_level` parameter]

### Other imputation algorithms

There are many different imputation algorithms. Here's just a selection of them for imputation of numerical data that could be applied to genotype data (to my understanding). For large datasets some algorithms have exceedingly long runtimes and large memory requirements.

- `missMethods::impute_sRHD` (Simple random hot deck imputation)
- `missMethods::impute_EM` (an EM imputation algorithm)
- `softImpute::softImpute` (Imputation with nuclear-norm regularization)
- `mice::mice(method = 'pmm')` (Multivariate Imputation by Chained Equations: Predictive Mean Matching)
- `Amelia::amelia` (another EM multiple imputation algorithm)
- `missForest::missForest` (Nonparametric imputation using Random Forest)
- `Hmisc::aregImpute` (Imputation using additive regression, bootstrapping, and predictive mean matching)
- `mi::mi` (Imputation in an approximate Bayesian framework)

```{r}
geno_matrix_small <- geno_matrix[,1:2000] # reduced dataset for performance reasons

geno_matrix_small %>%
  prcomp(geno_matrix) %>%
  tidy_pca_output() %>%
  plot_tidy_pca_simple()

geno_matrix_small %>% explore_filling_method(missMethods::impute_sRHD, destruction_level = 0.5)
#geno_matrix_small %>% explore_filling_method(missMethods::impute_EM, destruction_level = 0.5)
# high runtime and memory requirements
#geno_matrix_small %>% explore_filling_method(softImpute::softImpute, destruction_level = 0.5)
# fails with Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
#geno_matrix_small %>% explore_filling_method(mice::mice, destruction_level = 0.5, method = 'pmm')
# long runtime
#geno_matrix_small %>% explore_filling_method(Amelia::amelia, destruction_level = 0.5)
# fails with Amelia Error Code:  43, You have a variable in your dataset that does not vary.  Please remove this variable.
#geno_matrix_small %>% explore_filling_method(missForest::missForest, destruction_level = 0.5)
# long runtime
```

That was sobering.

#### Imputation in classes

Probably most (?) of these algorithms can be applied to meaningful subsets of data to leverage known context information. The missMethods package provides a useful helper function `impute_in_classes` for that.

```{r}
geno_matrix_small %>%
  shoot_holes_column_wise(0.5) %>%
  as.data.frame() %>%
  dplyr::mutate(Makro_Region = context_info$Makro_Region) %>%
  missMethods::impute_in_classes(cols_class = "Makro_Region", missMethods::impute_mean) %>%
  dplyr::select(-Makro_Region) %>%
  as.matrix() %>%
  prcomp(geno_matrix) %>%
  tidy_pca_output() %>%
  plot_tidy_pca_simple()
```

Note the strong effect of group-wise imputation!
